{"cells":[{"metadata":{"trusted":true},"cell_type":"raw","source":"%reset -f"},{"metadata":{},"cell_type":"markdown","source":"## imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom collections import defaultdict\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## read data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data():\n    train_pickle= '../input/riiid-cross-validation-files/cv1_train.pickle'\n    valid_pickle= '../input/riiid-cross-validation-files/cv1_valid.pickle'\n    \n    cols=['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n       'task_container_id', 'user_answer', 'answered_correctly',\n       'prior_question_elapsed_time', 'prior_question_had_explanation',\n       'max_time_stamp', 'rand_time_stamp', 'viretual_time_stamp']\n\n    cols_to_load= ['timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly',\n       'prior_question_elapsed_time', 'prior_question_had_explanation']\n    \n    train= pd.read_pickle(train_pickle)[cols_to_load]\n    valid= pd.read_pickle(valid_pickle)[cols_to_load]\n    \n        \n    return train,valid ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain,valid= read_data()\nprint(train.shape)\nprint(valid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_user_feats(df, user_sum_dict, user_count_dict):\n    '''to add user features only using past data for user'''\n    \n    user_sum_arr = np.zeros(len(df), dtype=np.int32)\n    user_count_arr= np.zeros(len(df), dtype=np.int32)\n    \n    for i, row in enumerate(tqdm(df[['user_id', 'answered_correctly']].values)):\n        user_sum_arr[i]= user_sum_dict[row[0]]\n        user_count_arr[i]= user_count_dict[row[0]]\n        \n        user_sum_dict[row[0]]+= row[1]\n        user_count_dict[row[0]]+= 1\n    \n        \n    df['user_correct_sum']= user_sum_arr\n    df['user_count']= user_count_arr\n    df['user_accuracy']= df['user_correct_sum']/df['user_count']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_user_feats_without_update(df,user_sum_dict, user_count_dict):\n    \n    user_sum_arr = np.zeros(len(df), dtype=np.int32)\n    user_count_arr= np.zeros(len(df), dtype=np.int32)\n\n    for i, row in enumerate(tqdm(df['user_id'].values)):\n        user_sum_arr[i]= user_sum_dict[row]\n        user_count_arr[i]= user_count_dict[row]\n    \n    df['user_correct_sum']= user_sum_arr\n    df['user_count']= user_count_arr\n    df['user_accuracy']= df['user_correct_sum']/df['user_count']\n    return df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_sum_dict= defaultdict(int)\nuser_count_dict= defaultdict(int)\n\ntrain = train.loc[train.content_type_id == False]\nvalid = valid.loc[valid.content_type_id == False]\n\ntrain= add_user_feats(train, user_sum_dict, user_count_dict)\nvalid= add_user_feats(valid, user_sum_dict, user_count_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_df = train.groupby('content_id', as_index= False).agg(\n    {'answered_correctly': ['count', 'mean']})\n\ncontent_df.columns = ['content_id', 'content_questions', 'content_mean']\n\ntrain = train.merge(content_df, on = \"content_id\", how = \"left\")\nvalid = valid.merge(content_df, on = \"content_id\", how = \"left\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# part\nquestion_file='../input/riiid-test-answer-prediction/questions.csv'\nquestions_df = pd.read_csv(question_file)\ntrain = pd.merge(train, questions_df[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\nvalid = pd.merge(valid, questions_df[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing dtype to avoid lightgbm error\ntrain['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int')\nvalid['prior_question_had_explanation'] = valid.prior_question_had_explanation.fillna(False).astype('int')\n\ntime_mean = train.prior_question_elapsed_time.dropna().values.mean()\ntrain['prior_question_elapsed_time'] = train.prior_question_elapsed_time.fillna(time_mean)\nvalid['prior_question_elapsed_time'] = valid.prior_question_elapsed_time.fillna(time_mean)\n\nvalid['user_accuracy'].fillna(0.65, inplace=True)\ntrain['user_accuracy'].fillna(0.65, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_mean= X.prior_question_elapsed_time.dropna().values.mean()\ntime_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FEATS= ['user_correct_sum', 'user_count', 'user_accuracy', 'content_questions',\n        'content_mean', 'prior_question_had_explanation', 'prior_question_elapsed_time',\n       'part', 'answered_correctly']\n\nvalid= valid[FEATS]\n\ntrain= train.iloc[-10000000:, :]\ntrain= train[FEATS]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= train.drop('answered_correctly', axis=1)\ny= train.loc[ :, 'answered_correctly']\n\nprint(X.shape)\nprint(y.shape)\n\nX_val= valid.drop('answered_correctly', axis=1)\ny_val= valid.loc[ :, 'answered_correctly']\n\n\nprint(X_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train\ndel valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['prior_question_had_explanation'] = X.prior_question_had_explanation.fillna(False).astype('int')\nX_val['prior_question_had_explanation'] = X_val.prior_question_had_explanation.fillna(False).astype('int')\nX.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nlgb_train = lgb.Dataset(X, y)\nlgb_valid = lgb.Dataset(X_val, y_val)\n\n\nmodel = lgb.train(\n                    {'objective': 'binary'}, \n                    lgb_train,\n                    valid_sets=[lgb_train, lgb_valid],\n                    verbose_eval=100,\n                    num_boost_round=10000,\n                    early_stopping_rounds=10\n                )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score as auc\npred= model.predict(X_val)\nprint(auc(y_val, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyperparam tuning for gbdt\n# from sklearn.ensemble import GradientBoostingClassifier\n# from sklearn.metrics import roc_auc_score as auc\n\n# params= {\n#     'learning_rate': [0.05,0.1,0.15],\n#     'n_estimators': [100, 200],\n#     'max_depth': [3, 7]\n# }\n\n\n# for lr in params['learning_rate']:\n#     for est in params['n_estimators']:\n#         for d in params['max_depth']:\n#             print('LR :', lr, 'Est :', est, 'D :', d)\n#             gbdt = GradientBoostingClassifier(learning_rate= lr, n_estimators=est, max_depth=d)\n#             gbdt.fit(X,y)\n#             pred= gbdt.predict_proba(X_val)[:, 1]\n#             print(auc(y_val, pred))\n            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import GradientBoostingClassifier\n# gbdt = GradientBoostingClassifier()\n# gbdt.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import roc_auc_score as auc\n# X_val= valid.drop('answered_correctly', axis=1)\n# y_val= valid.loc[ :, 'answered_correctly']\n\n# pred= gbdt.predict_proba(X_val)[:, 1]\n# auc(y_val, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test= pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FEAT= ['user_correct_sum', 'user_count', 'user_accuracy', 'content_questions',\n        'content_mean', 'prior_question_had_explanation', 'prior_question_elapsed_time',\n       'part']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_and_predict(test):\n    test= test.merge(content_df, on = \"content_id\", how = \"left\")\n    test= add_user_feats_without_update(test,user_sum_dict, user_count_dict)\n    test= pd.merge(test, questions_df[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n    \n    \n    te= test.loc[ :, FEAT]\n    te['content_questions'].fillna(0, inplace = True)\n    te['content_mean'].fillna(0.65, inplace = True)\n    te['user_correct_sum'].fillna(0, inplace = True)\n    te['user_count'].fillna(0, inplace = True)\n    te['user_accuracy'].fillna(0.65, inplace = True)\n    te['part'].fillna(7, inplace = True)\n    \n    \n    te['prior_question_had_explanation'] = te.prior_question_had_explanation.fillna(False).astype('int')\n    te['prior_question_elapsed_time'] = te.prior_question_elapsed_time.fillna(25000)\n    \n    \n    \n\n    pred= model.predict(te)\n    test['answered_correctly']=pred\n    \n    return test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t= process_and_predict(test)\nt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\nenv = riiideducation.make_env()\n\n# Training data is in the competition dataset as usual\n\niter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test:\n    test_results= process_and_predict(test_df)\n    env.predict(test_results.loc[test_results['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}